{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "rational-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from brate_trainer_mlp_lstm import *\n",
    "from data_columns import *\n",
    "import load_data as ld\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "banner-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = {\n",
    "    'aggr_wind_size': '12', \n",
    "    'horz_wind_size': '2'\n",
    "}\n",
    "model_types = ['rf', 'xgb', 'mlp', 'lstm']\n",
    "brate_model_num = {\n",
    "    'rf': 201,\n",
    "    'xgb': 201,\n",
    "    'mlp': 201,\n",
    "    'lstm': 201\n",
    "}\n",
    "\n",
    "#tf.device('cpu')\n",
    "# rf: brate:3, nseg:4\n",
    "# xgb: brate:3, nseg:4\n",
    "# mlp: brate:5, nseg:17\n",
    "# lstm: brate:2, nseg:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "challenging-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run6wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run6wsize2_rf.csv\n",
      "run27wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run27wsize2_rf.csv\n",
      "run21wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run21wsize2_rf.csv\n",
      "run12wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run12wsize2_rf.csv\n",
      "run6wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run6wsize2_xgb.csv\n",
      "run27wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run27wsize2_xgb.csv\n",
      "run21wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run21wsize2_xgb.csv\n",
      "run12wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run12wsize2_xgb.csv\n",
      "run6wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run6wsize2_mlp.csv\n",
      "run27wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run27wsize2_mlp.csv\n",
      "run21wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run21wsize2_mlp.csv\n",
      "run12wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run12wsize2_mlp.csv\n",
      "run6wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run6wsize2_lstm.csv\n",
      "run27wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run27wsize2_lstm.csv\n",
      "run21wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run21wsize2_lstm.csv\n",
      "run12wsize2.csv\n",
      "../data/data_eval_output/dataset7-2sWsize-12aggsize/run12wsize2_lstm.csv\n"
     ]
    }
   ],
   "source": [
    "for model_type in model_types:\n",
    "    with tf.device('/cpu:0'):\n",
    "\n",
    "        train_data_dir = '../data/data_train/dataset7-' \\\n",
    "                                + PARAMETERS['horz_wind_size'] + 'sWsize-' \\\n",
    "                                + PARAMETERS['aggr_wind_size'] + 'aggsize/'\n",
    "        eval_data_dir = '../data/data_eval/dataset7-' \\\n",
    "                                    + PARAMETERS['horz_wind_size'] + 'sWsize-' \\\n",
    "                                    + PARAMETERS['aggr_wind_size'] + 'aggsize/'\n",
    "        brate_model_path = '../models/'+model_type+'/model' \\\n",
    "                                        +str(brate_model_num[model_type])+'/'\n",
    "        scaler_filename = '../models/'+'mlp'+'/model' \\\n",
    "                                        +str(brate_model_num['mlp'])+'/'+'X_scaler.pkl'\n",
    "        #scaler_filename = brate_model_path +'X_scaler.pkl'\n",
    "        eval_csvs = ld.get_files_in_subdirectory(eval_data_dir)\n",
    "        # Parent dir for saving results\n",
    "        eval_out_dir = '../data/data_eval_output/dataset7-' \\\n",
    "                                + PARAMETERS['horz_wind_size'] + 'sWsize-' \\\n",
    "                                + PARAMETERS['aggr_wind_size'] + 'aggsize/'\n",
    "        if not os.path.exists(eval_out_dir):\n",
    "            os.makedirs(eval_out_dir)\n",
    "            \n",
    "        if model_type == 'rf' or model_type == 'xgb':\n",
    "            dir_brate = brate_model_path + \"brate_classifier.pkl\"\n",
    "            with open(dir_brate, 'rb') as f:\n",
    "                model_dict = pickle.load(f)    \n",
    "            model_brate = model_dict[\"classifier\"]\n",
    "        elif model_type == 'mlp' or model_type == 'lstm':\n",
    "            model_brate = load_model(brate_model_path)\n",
    "        else:\n",
    "            print('Do not know what you are asking me to do')\n",
    "\n",
    "        for file in eval_csvs:\n",
    "            print(file)\n",
    "            df_eval = pd.read_csv(eval_data_dir + file)\n",
    "            # Path to save the resulting evaluation data\n",
    "            out_file = file.replace('.csv', \n",
    "                                    '_'+model_type+'.csv')\n",
    "            dir_eval_out = eval_out_dir + out_file\n",
    "            print(dir_eval_out)\n",
    "            cols_eval_df = ['Thor_start', 'Thor_end', 'Node', 'video-Id', \n",
    "                            'last-SegId', 'n-PredSeg', 'n-PredSeg-TRUE',\n",
    "                            'mode-SegQuality', 'baseStatAssoc']\n",
    "            df_eval_result = pd.DataFrame(columns=cols_eval_df)        \n",
    "            df_eval_result = df_eval[['Thor_start', 'Thor_end', 'Node', 'video-Id', 'last-SegId']].copy()\n",
    "            # Extract X and Y for predictors\n",
    "            # X and y here are real values\n",
    "            X_brate = df_eval[FEAT_COLS].to_numpy()\n",
    "            y_brate = df_eval[TARGET_SEGMODE].to_numpy().squeeze()\n",
    "            y_nseg = df_eval[TARGET_SEGNUMBER].to_numpy().squeeze()\n",
    "            y_gnb = df_eval[TARGET_CELLIDASSOC].to_numpy().squeeze()\n",
    "\n",
    "            if (model_type == 'rf') or (model_type == 'xgb'):    \n",
    "                yhat_brate = model_brate.predict(X_brate)\n",
    "                #print('yhat_brate: ',yhat_brate)\n",
    "\n",
    "            if (model_type == 'mlp') or (model_type == 'lstm'):\n",
    "                # normalize \n",
    "                #brate_scaler = MinMaxScaler()\n",
    "                #nseg_scaler = MinMaxScaler()\n",
    "                #X_brate = brate_scaler.fit_transform(X_brate)\n",
    "                #X_nseg = nseg_scaler.fit_transform(X_nseg)\n",
    "\n",
    "                # Get the scaler created using the train set. This should have been saved while training or preprocessing \n",
    "                # and loaded along with the model when predicting for eval dataset. But I have not saved this, so I am just using the train set \n",
    "                # to re-create this scaler \n",
    "                df_train = ld.load_rf_trainer_data(train_data_dir, verbose=False)\n",
    "                df_train = df_train.astype('float32')\n",
    "                df_train = df_train[~df_train.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "                df_train_brate = df_train.loc[df_train[TARGET_SEGMODE[0]] > 0.0].copy()\n",
    "                X_train = df_train[FEAT_COLS].values\n",
    "                # load the saved scaler \n",
    "                X_scaler = joblib.load(scaler_filename) \n",
    "                #X_scaler = MinMaxScaler()\n",
    "                #X_scaler.fit(X_train)\n",
    "                X_brate = X_scaler.transform(X_brate)\n",
    "\n",
    "\n",
    "                if (model_type == 'lstm'):\n",
    "                    # reshape X with extra dimension for lstm\n",
    "                    X_brate = X_brate.reshape((X_brate.shape[0], \n",
    "                                      1, X_brate.shape[1]))\n",
    "\n",
    "                # brate      \n",
    "                yhat_brate = model_brate.predict(X_brate)\n",
    "                # y is OHE. convert y to integer encoded\n",
    "                yhat_brate = np.argmax(yhat_brate, axis=1)\n",
    "                # convert integer encoded to actual bitrate values\n",
    "\n",
    "                yhat_brate = np.array(BITRATE_LIST)[yhat_brate]\n",
    "\n",
    "            #new\n",
    "            # yhat_nseg is only 0 or 1\n",
    "            # should this be matched to the y_nseg ?\n",
    "            # Even though the segment is actually requested right after the aggregation window \n",
    "            # where the previous request was seen and we waited until the request was actually \n",
    "            # sent out to evaluate if we actually right.\n",
    "            # So we are shifting the yhat_nseg until the window where it is actually evaluated. . \n",
    "            # basically propagating it, like we did with the features\n",
    "            # So....every window where > 0 y_nseg exists we have a 1 yhat_nseg and when y_nseg is 0\n",
    "            # yhat_nseg is also 0. \n",
    "            # This is assuming that, if a segments are requested in consequtive windows, we are able to fetch \n",
    "            # it in time.  \n",
    "            yhat_nseg = np.where(y_nseg == 0, 0, 1)\n",
    "            # Set to 0 samples where there are be no ground truth segment requests in horz window \n",
    "            yhat_brate = np.where(y_nseg == 0, 0, yhat_brate)\n",
    "\n",
    "\n",
    "            df_eval_result.loc[:,'n-PredSeg-TRUE'] = y_nseg.copy() \n",
    "            df_eval_result.loc[:,'n-PredSeg'] = yhat_nseg.copy() \n",
    "            df_eval_result.loc[:,'mode-SegQuality'] = yhat_brate.copy() \n",
    "            df_eval_result.loc[:,'baseStatAssoc'] = y_gnb.copy() \n",
    "\n",
    "            # Saving evaluation file\n",
    "            df_eval_result = df_eval_result.rename(columns={\"Thor_start\": \"Tpred_start\", 'Thor_end': \"Tpred_end\"})\n",
    "            df_eval_result = df_eval_result.sort_values(['Tpred_start', 'Tpred_end', 'Node'])\n",
    "            df_eval_result.to_csv(dir_eval_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-prediction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-utilization",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
